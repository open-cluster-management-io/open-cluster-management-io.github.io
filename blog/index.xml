<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog on Open Cluster Management</title><link>https://open-cluster-management.io/blog/</link><description>Recent content in Blog on Open Cluster Management</description><generator>Hugo</generator><language>en</language><atom:link href="https://open-cluster-management.io/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>Open Cluster Management 社区诚邀您共赴 KubeCon China 2025 探讨多集群管理新未来</title><link>https://open-cluster-management.io/blog/2025/open-cluster-management-%E7%A4%BE%E5%8C%BA%E8%AF%9A%E9%82%80%E6%82%A8%E5%85%B1%E8%B5%B4-kubecon-china-2025-%E6%8E%A2%E8%AE%A8%E5%A4%9A%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86%E6%96%B0%E6%9C%AA%E6%9D%A5/</link><pubDate>Thu, 22 May 2025 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2025/open-cluster-management-%E7%A4%BE%E5%8C%BA%E8%AF%9A%E9%82%80%E6%82%A8%E5%85%B1%E8%B5%B4-kubecon-china-2025-%E6%8E%A2%E8%AE%A8%E5%A4%9A%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86%E6%96%B0%E6%9C%AA%E6%9D%A5/</guid><description>KubeCon + CloudNativeCon China 2025 即将于6 月 10-11 日在香港盛大举行，这是云原生领域最具影响力的技术盛会之一。作为云原生多集群管理领域的领军项目之一，Open Cluster Management (OCM) 社区将带来三个精彩议题，与您共同探讨多集群管理领域的最新创新和突破。在这里，您将有机会与来自全球的云原生专家面对面交流，深入了解 OCM 如何通过创新的技术方案，帮助企业应对日益复杂的多集群管理挑战，开启云原生多集群管理的新篇章。
议题信息 闪电演讲：使用OCM Addon简化多集群集成 时间：6 月 10 日 11:42 - 11:47 HKT
地点：Level 16 | Grand Ballroom I
演讲者：Jian Zhu (Red Hat)
在这个闪电演讲中，Jian Zhu 将介绍 OCM 的 Addon 机制，展示如何通过简单的 YAML 文件实现多集群能力的扩展。主要内容包括：
OCM Addon 机制概述及其在多集群环境中的作用 项目集成案例：以 Fluid 为例，展示如何通过 Addon 增强多集群管理能力 AddonTemplate API：简化 addon 创建和管理的创新方案 实际应用价值：展示 OCM Addons 的效率和可扩展性 解锁 CEL 在多集群调度中的强大能力 时间：6 月 10 日 17:00 - 17:30 HKT</description></item><item><title>Joining OCM Hub and Spoke using AWS IRSA authentication</title><link>https://open-cluster-management.io/blog/2024/joining-ocm-hub-and-spoke-using-aws-irsa-authentication/</link><pubDate>Mon, 02 Dec 2024 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2024/joining-ocm-hub-and-spoke-using-aws-irsa-authentication/</guid><description>Refer this solution.</description></item><item><title>KubeCon NA 2024 - Scheduling AI Workload Among Multiple Clusters</title><link>https://open-cluster-management.io/blog/2024/kubecon-na-2024-scheduling-ai-workload-among-multiple-clusters/</link><pubDate>Tue, 12 Nov 2024 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2024/kubecon-na-2024-scheduling-ai-workload-among-multiple-clusters/</guid><description>Read more at KubeCon NA 2024 - Open Cluster Management: Scheduling AI Workload Among Multiple Clusters | Project Lightning Talk | video.</description></item><item><title>KubeDay Australia 2024 - Open Sourcing the Open Cluster Management Project and the Lessons We Can Learn for AI</title><link>https://open-cluster-management.io/blog/2024/kubeday-australia-2024-open-sourcing-the-open-cluster-management-project-and-the-lessons-we-can-learn-for-ai/</link><pubDate>Tue, 15 Oct 2024 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2024/kubeday-australia-2024-open-sourcing-the-open-cluster-management-project-and-the-lessons-we-can-learn-for-ai/</guid><description>Read more at KubeDay Australia 2024 - Open Sourcing the Open Cluster Management Project and the Lessons We Can Learn for AI | video.</description></item><item><title>KubeCon CN 2024 - Boundaryless Computing: Optimizing LLM Performance, Cost, and Efficiency in Multi-Cloud Architecture | 无边界计算：在多云架构中优化LLM性能、成本和效率</title><link>https://open-cluster-management.io/blog/2024/kubecon-cn-2024-boundaryless-computing-optimizing-llm-performance-cost-and-efficiency-in-multi-cloud-architecture-%E6%97%A0%E8%BE%B9%E7%95%8C%E8%AE%A1%E7%AE%97%E5%9C%A8%E5%A4%9A%E4%BA%91%E6%9E%B6%E6%9E%84%E4%B8%AD%E4%BC%98%E5%8C%96llm%E6%80%A7%E8%83%BD%E6%88%90%E6%9C%AC%E5%92%8C%E6%95%88%E7%8E%87/</link><pubDate>Wed, 21 Aug 2024 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2024/kubecon-cn-2024-boundaryless-computing-optimizing-llm-performance-cost-and-efficiency-in-multi-cloud-architecture-%E6%97%A0%E8%BE%B9%E7%95%8C%E8%AE%A1%E7%AE%97%E5%9C%A8%E5%A4%9A%E4%BA%91%E6%9E%B6%E6%9E%84%E4%B8%AD%E4%BC%98%E5%8C%96llm%E6%80%A7%E8%83%BD%E6%88%90%E6%9C%AC%E5%92%8C%E6%95%88%E7%8E%87/</guid><description>Read more at KubeCon CN 2024 - Boundaryless Computing: Optimizing LLM Performance, Cost, and Efficiency in Multi-Cloud Architecture.</description></item><item><title>KubeCon CN 2024 - Connecting the Dots: Towards a Unified Multi-Cluster AI/ML Experience | 连接点：走向统一的多集群AI/ML体验</title><link>https://open-cluster-management.io/blog/2024/kubecon-cn-2024-connecting-the-dots-towards-a-unified-multi-cluster-ai/ml-experience-%E8%BF%9E%E6%8E%A5%E7%82%B9%E8%B5%B0%E5%90%91%E7%BB%9F%E4%B8%80%E7%9A%84%E5%A4%9A%E9%9B%86%E7%BE%A4ai/ml%E4%BD%93%E9%AA%8C/</link><pubDate>Wed, 21 Aug 2024 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2024/kubecon-cn-2024-connecting-the-dots-towards-a-unified-multi-cluster-ai/ml-experience-%E8%BF%9E%E6%8E%A5%E7%82%B9%E8%B5%B0%E5%90%91%E7%BB%9F%E4%B8%80%E7%9A%84%E5%A4%9A%E9%9B%86%E7%BE%A4ai/ml%E4%BD%93%E9%AA%8C/</guid><description>Read more at KubeCon CN 2024 - Connecting the Dots: Towards a Unified Multi-Cluster AI/ML Experience.</description></item><item><title>KubeCon CN 2024 - Extend Kubernetes to Edge Using Event-Based Transport | 使用基于事件的传输将Kubernetes扩展到边缘</title><link>https://open-cluster-management.io/blog/2024/kubecon-cn-2024-extend-kubernetes-to-edge-using-event-based-transport-%E4%BD%BF%E7%94%A8%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E4%BC%A0%E8%BE%93%E5%B0%86kubernetes%E6%89%A9%E5%B1%95%E5%88%B0%E8%BE%B9%E7%BC%98/</link><pubDate>Wed, 21 Aug 2024 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2024/kubecon-cn-2024-extend-kubernetes-to-edge-using-event-based-transport-%E4%BD%BF%E7%94%A8%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9A%84%E4%BC%A0%E8%BE%93%E5%B0%86kubernetes%E6%89%A9%E5%B1%95%E5%88%B0%E8%BE%B9%E7%BC%98/</guid><description>Read more at KubeCon CN 2024 - Extend Kubernetes to Edge Using Event-Based Transport.</description></item><item><title>The HA Hub clusters solution -- MultipleHubs</title><link>https://open-cluster-management.io/blog/2024/the-ha-hub-clusters-solution--multiplehubs/</link><pubDate>Sun, 11 Aug 2024 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2024/the-ha-hub-clusters-solution--multiplehubs/</guid><description>The MultipleHubs is a new feature in Open Cluster Management (OCM) that allows you to configure a list of bootstrapkubeconfigs of multiple hubs. This feature is designed to provide a high availability (HA) solution of hub clusters. In this blog, we will introduce the MultipleHubs feature and how to use it.
The high availability of hub clusters means that if one hub cluster is down, the managed clusters can still communicate with other hub clusters.</description></item><item><title>Using the GitOps way to deal with the upgrade challenges of multi-cluster tool chains</title><link>https://open-cluster-management.io/blog/2024/using-the-gitops-way-to-deal-with-the-upgrade-challenges-of-multi-cluster-tool-chains/</link><pubDate>Fri, 19 Jan 2024 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2024/using-the-gitops-way-to-deal-with-the-upgrade-challenges-of-multi-cluster-tool-chains/</guid><description>Upgrading challenges of tool chains in multi-cluster environments Open Cluster Management (OCM) is a community-driven project focused on multicluster and multicloud scenarios for Kubernetes applications. It provides functions such as cluster registration, application and workload distribution, and scheduling. Add-on is an extension mechanism based on the foundation components provided by OCM, which allows applications in the Kubernetes ecosystem to be easily migrated to the OCM platform and has the ability to orchestrate and schedule across multiple clusters and multiple clouds.</description></item><item><title>Open Cluster Management - Configuring Your Kubernetes Fleet With the Policy Addon</title><link>https://open-cluster-management.io/blog/2023/open-cluster-management-configuring-your-kubernetes-fleet-with-the-policy-addon/</link><pubDate>Wed, 22 Nov 2023 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2023/open-cluster-management-configuring-your-kubernetes-fleet-with-the-policy-addon/</guid><description>View the video at YouTube.</description></item><item><title>以GitOps方式应对多集群工具链的升级挑战</title><link>https://open-cluster-management.io/blog/2023/%E4%BB%A5gitops%E6%96%B9%E5%BC%8F%E5%BA%94%E5%AF%B9%E5%A4%9A%E9%9B%86%E7%BE%A4%E5%B7%A5%E5%85%B7%E9%93%BE%E7%9A%84%E5%8D%87%E7%BA%A7%E6%8C%91%E6%88%98/</link><pubDate>Fri, 27 Oct 2023 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2023/%E4%BB%A5gitops%E6%96%B9%E5%BC%8F%E5%BA%94%E5%AF%B9%E5%A4%9A%E9%9B%86%E7%BE%A4%E5%B7%A5%E5%85%B7%E9%93%BE%E7%9A%84%E5%8D%87%E7%BA%A7%E6%8C%91%E6%88%98/</guid><description>多集群环境下工具链的升级挑战 OCM（open-cluster-management）是一个专注于 Kubernetes 应用跨多集群和多云的管理平台，提供了集群的注册，应用和负载的分发，调度等基础功能。Add-on 插件是 OCM 提供的一种基于基础组件的扩展机制，可以让 Kubernetes 生态的应用很容易迁移到 OCM 平台上，拥有跨多集群多云的编排和调度的能力。如 Istio，Prometheus，Submarine 可以通过 Add-on 的方式扩展至多集群。在多集群环境中，如何优雅、平滑地升级整个工具链（比如 Istio、Prometheus 和其他工具）是我们在多集群管理中遇到的挑战，工具链的升级失败可能会导致数千个用户工作负载无法访问。因此，找到一种简单、安全的跨集群升级解决方案变得非常重要。
本文我们将介绍 Open Cluster Management(OCM)如何将工具链升级视为配置文件的变更，使用户能够利用 Kustomize 或 GitOps 实现跨集群的无缝滚动/金丝雀升级。
在正式开始前，首先介绍几个 OCM 中的概念。
add-on 插件 在 OCM 平台上，add-on 插件可以实现在不同托管集群（Spoke）上应用不同的配置，也可以实现从控制面（Hub）获取数据到 Spoke 集群上等功能。比如：你可以使用managed-serviceaccount 插件在 Spoke 集群上将指定的 ServiceaCount 信息返回给 Hub 集群，可以使用cluster-proxy插件建立一个从 spoke 到 hub 的反向代理通道。
现阶段 OCM 社区已经有的一些 add-on：
Multicluster Mesh Addon 可用于管理（发现、部署和联合）OCM 中跨多个集群的服务网格。 Submarine Addon 让Submarine 和 OCM 方便集成，在 hub cluster 上部署 Submariner Broker，在 managed cluster 上部署所需的 Submariner 组件, 为托管集群提供跨集群的 Pod 和 Service 网络互相访问的能力。 Open-telemetry add-on 自动在 hub cluster 和 managed cluster 上 安装 otelCollector，并在 hub cluster 上自动安装 jaeger-all-in-one 以处理和存储 traces。 Application lifecycle management 实现多集群或多云环境中的应用程序生命周期管理。add-on 插件提供了一套通过 Subscriptions 订阅 channel，将 github 仓库，Helm release 或者对象存储仓库的应用分发到指定 Spoke 集群上的机制。 Policy framework和Policy controllers add-on 插件可以让 Hub 集群管理员很轻松为 Spoke 集群部署安全相关的 policy 策略。 Managed service account add-on 插件可以让 Hub 集群管理员很容易管理 Spoke 集群上 serviceaccount。 Cluster proxy add-on 插件通过反向代理通道提供了 Hub 和 Spoke 集群之间 L4 网络连接。 更多关于 add-on 插件的介绍可以参考详解 OCM add-on 插件。</description></item><item><title>详解OCM add-on插件</title><link>https://open-cluster-management.io/blog/2023/%E8%AF%A6%E8%A7%A3ocm-add-on%E6%8F%92%E4%BB%B6/</link><pubDate>Wed, 24 May 2023 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2023/%E8%AF%A6%E8%A7%A3ocm-add-on%E6%8F%92%E4%BB%B6/</guid><description>OCM add-on插件概述 OCM （open-cluster-management）是一个专注于Kubernetes应用跨多集群和多云的管理平台， 提供了集群的注册，应用和负载的分发，调度等基础功能。Add-on插件是OCM提供的一种基于基础组建 的扩展机制，可以让Kubernetes生态的应用很容易迁移到OCM平台上，拥有跨多集群多云的编排和调度的能力。
在OCM平台上，add-on插件可以实现不同被管理集群（Spoke）上应用的不同的配置，也可以实现从控制面（Hub） 获取数据到Spoke集群上等功能。比如：你可以使用managed-serviceaccount add-on插件在Spoke集群上将指定的ServiceaCount信息返回给Hub集群，可以使用cluster-proxy add-on插件建立一个从spoke到hub的反向代理通道。
现阶段OCM社区已经有的一些add-on：
Application lifecycle management add-on插件提供了一套通过Subscriptions订阅channel，将github仓库，Helm release或者对象存储仓库的应用分发到指定Spoke集群上的机制。 Cluster proxy add-on插件通过反向代理通道提供了Hub和Spoke集群之间L4网络连接。 Managed service account add-on插件可以让Hub集群管理员很容易管理Spoke集群上serviceaccount。 Policy framework 和 Policy controllers add-on插件可以让Hub集群管理员很轻松为Spoke集群部署安全相关的policy策略。 Submarine Addon add-on插件可以让Submarine 和OCM方便集成，为被管理集群提供跨集群的Pod和Service网络互相访问的能力。 Multicluster Mesh Addon add-on插件为OCM被管理集群提供了跨集群Service Mesh服务。 本文将详细介绍add-on插件的实现机制。
OCM add-on 插件实现机制 通常情况下一个add-on插件包含2部分组成：
Add-on Agent 是运行在Spoke集群上的任何Kubernetes资源，比如可以是一个有访问Hub权限的Pod，可以是一个Operator，等等。 Add-on Manager 是运行中Hub集群上的一个Kubernetes控制器。这个控制器可以通过ManifestWork 来给不同Spoke集群部署分发Add-on Agent所需要的Kubernetes资源, 也可以管理Add-on Agent所需要的权限等。 在OCM Hub集群上，关于add-on插件有2个主要的API：
ClusterManagementAddOn: 这是一个cluster-scoped的API，每个add-on插件必须创建一个同名的实例用来描述add-on插件的名字 和描述信息，以及配置，安装部署策略等。 ManagedClusterAddOn: 这是一个namespace-scoped的API，部署到spoke集群的namespace下的和add-on同名的实例用来触发 Add-on Agent安装部署到该Spoke集群。我们也可以通过这个API获取这个add-on插件的agent的健康状态信息。 Add-on 插件架构如下：
创建：
Add-on Manager 监控managedClusterAddOn 来创建manifestWork把Add-on Agent部署到Spoke集群上，也可以根据 配置的部署策略只将agent部署到策略选中的集群上。</description></item><item><title>使用OCM让多集群调度更具可扩展性</title><link>https://open-cluster-management.io/blog/2023/%E4%BD%BF%E7%94%A8ocm%E8%AE%A9%E5%A4%9A%E9%9B%86%E7%BE%A4%E8%B0%83%E5%BA%A6%E6%9B%B4%E5%85%B7%E5%8F%AF%E6%89%A9%E5%B1%95%E6%80%A7/</link><pubDate>Wed, 10 May 2023 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2023/%E4%BD%BF%E7%94%A8ocm%E8%AE%A9%E5%A4%9A%E9%9B%86%E7%BE%A4%E8%B0%83%E5%BA%A6%E6%9B%B4%E5%85%B7%E5%8F%AF%E6%89%A9%E5%B1%95%E6%80%A7/</guid><description>背景问题 OCM Placement API 可以动态的在多集群环境中选择一组托管集群ManagedCluster，以便将工作负载部署到这些集群上。
在上一篇CNCF 沙箱项目 OCM Placement 多集群调度指南中，我们详细介绍了 Placement 的基本概念，提供的调度功能以及调度流程。同时还通过示例展示了如何在不同的应用场景下使用 Placement API。建议首次接触 Placement 的读者先阅读此文。
Placement 提供了通过标签选择器labelSelector或声明选择器claimSelector过滤集群，同时也提供了一些内置的优选器prioritizer，可对过滤后的集群进行打分排序和优先选择。 内置的prioritizer中包括了最大可分配 CPU 资源(ResourceAllocatableCPU)和最大可分配内存资源(ResourceAllocatableMemory)，它们提供了根据集群的可分配 CPU 和内存进行调度的能力。但是，由于集群的&amp;quot;AllocatableCPU&amp;quot;和&amp;quot;AllocatableMemory&amp;quot;是静态值，即使&amp;quot;集群资源不足&amp;quot;，它们也不会改变。这导致在实际使用中，这两个prioritizer不能满足基于实时可用 CPU 或内存进行调度的需求。此外，使用者还可能需要根据从集群中获取的资源监控数据进行调度，这些都是内置的prioritizer无法满足的需求。
以上这些需求要求 Placement 能够更灵活的根据第三方数据来进行调度。为此，我们实现了一种更具扩展性的方式来支持基于第三方数据的调度，使用者可以使用自定义的分数来选择集群。
本文将介绍 OCM 是如何让多集群调度更具可扩展性，并通过实例展示如何实现一个第三方数据控制器controller来扩展 OCM 的多集群调度功能。
OCM 如何让调度具有可扩展性 为了实现基于第三方数据的调度，OCM 引入了 API AddOnPlacementScore，它支持存储自定义的集群分数，使用者可以在 Placement 中指定使用此分数选择集群。
如下是一个AddOnPlacementScore的例子，更多关于 API 的细节可访问types_addonplacementscore.go。
apiVersion: cluster.open-cluster-management.io/v1alpha1 kind: AddOnPlacementScore metadata: name: default namespace: cluster1 status: conditions: - lastTransitionTime: &amp;#34;2021-10-28T08:31:39Z&amp;#34; message: AddOnPlacementScore updated successfully reason: AddOnPlacementScoreUpdated status: &amp;#34;True&amp;#34; type: AddOnPlacementScoreUpdated validUntil: &amp;#34;2021-10-29T18:31:39Z&amp;#34; scores: - name: &amp;#34;cpuAvailable&amp;#34; value: 66 - name: &amp;#34;memAvailable&amp;#34; value: 55 AddOnPlacementScore的主要内容都在status中，因为我们不希望使用者更新它。AddOnPlacementScore的生命周期维护及scores的更新应该由第三方controller负责。</description></item><item><title>How to distribute workloads using Open Cluster Management</title><link>https://open-cluster-management.io/blog/2023/how-to-distribute-workloads-using-open-cluster-management/</link><pubDate>Thu, 19 Jan 2023 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2023/how-to-distribute-workloads-using-open-cluster-management/</guid><description>Read more at Red Hat Developers.</description></item><item><title>KubeCon NA 2022 - OCM Multicluster App &amp; Config Management</title><link>https://open-cluster-management.io/blog/2022/kubecon-na-2022-ocm-multicluster-app-config-management/</link><pubDate>Wed, 26 Oct 2022 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2022/kubecon-na-2022-ocm-multicluster-app-config-management/</guid><description>Read more at KubeCon NA 2022 - OCM Multicluster App &amp;amp; Config Management.</description></item><item><title>KubeCon NA 2022 - OCM Workload distribution with Placement API</title><link>https://open-cluster-management.io/blog/2022/kubecon-na-2022-ocm-workload-distribution-with-placement-api/</link><pubDate>Wed, 26 Oct 2022 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2022/kubecon-na-2022-ocm-workload-distribution-with-placement-api/</guid><description>Read more at KubeCon NA 2022 - OCM Workload distribution with Placement API.</description></item><item><title>Karmada and Open Cluster Management: two new approaches to the multicluster fleet management challenge</title><link>https://open-cluster-management.io/blog/2022/karmada-and-open-cluster-management-two-new-approaches-to-the-multicluster-fleet-management-challenge/</link><pubDate>Mon, 26 Sep 2022 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2022/karmada-and-open-cluster-management-two-new-approaches-to-the-multicluster-fleet-management-challenge/</guid><description>Read more at CNCF Blog.</description></item><item><title>Extending the Multicluster Scheduling Capabilities with Open Cluster Management Placement</title><link>https://open-cluster-management.io/blog/2022/extending-the-multicluster-scheduling-capabilities-with-open-cluster-management-placement/</link><pubDate>Thu, 15 Sep 2022 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2022/extending-the-multicluster-scheduling-capabilities-with-open-cluster-management-placement/</guid><description>Read more at Red Hat Cloud Blog.</description></item><item><title>详解ocm klusterlet秘钥管理机制</title><link>https://open-cluster-management.io/blog/2022/%E8%AF%A6%E8%A7%A3ocm-klusterlet%E7%A7%98%E9%92%A5%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6/</link><pubDate>Mon, 25 Apr 2022 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2022/%E8%AF%A6%E8%A7%A3ocm-klusterlet%E7%A7%98%E9%92%A5%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6/</guid><description>概述 在open-cluster-management中，为了使控制面有更好的可扩展性，我们使用了hub-spoke的架构：即集中的控制面（hub只 负责处理控制面的资源和数据而无需访问被管理的集群；每个被管理集群（spoke）运行一个称为klusterlet的agent访问控制面获取 需要执行的任务。在这个过程中，klusterlet需要拥有访问hub集群的秘钥才能和hub安全通信。确保秘钥的安全性是非常重要的， 因为如果这个秘钥被泄露的话有可能导致对hub集群的恶意访问或者窃取敏感信息，特别是当ocm的被管理集群分布在不同的公有云中的时候。 为了保证秘钥的安全性，我们需要满足一些特定的需求：
尽量避免秘钥在公有网络中的传输 秘钥的刷新和废除 细粒度的权限控制 本文将详细介绍ocm是如何实现秘钥的管理来保证控制面板和被管理集群之间的安全访问的。
架构和机制 在ocm中我们采用了以下几个机制来确保控制面和被管理集群之间访问的安全性：
基于CertificateSigniningRequest的mutual tls 双向握手协议和动态klusterletID 认证和授权的分离 基于CertificateSigniningRequest的mutual tls 使用kubernetes的CertificateSigniningRequest（CSR）API可以方便的生成客户认证证书。这个机制可以让klusterlet在第一次 启动访问hub集群时使用一个权限很小的秘钥来创建CSR。当CSR返回了生成的证书后，klusterlet就可以用后续生成的带有更大访问权限的 证书来访问hub集群。在使用csr的过程中，klusterlet的私钥不会在网络中传输而是一直保存在被管理集群中；只有CSR的公钥和初始阶段需要的 小权限秘钥（bootstrap secret）会在不同集群间传输。这就最大程度的保证秘钥不会在传输过程中被泄露出去。
双向握手协议和动态klusterletID 那么如果初始阶段的bootstrap secret被泄露了会怎么样呢？这就牵涉到OCM中的双向握手协议。当被管理集群中的klusterlet使用bootstrap secret 发起了第一次请求的时候, hub集群不会立刻为这个请求创建客户证书和对应的访问权限。这个请求将处在Pending状态，直到hub集群拥有特定管理权限的管理员 同意了klusterlet的接入请求后，客户证书和特定权限才会被创建出来。这个请求中包含了klusterlet启动阶段生成的动态ID，管理员需要确保这个ID和被 管理集群上klusterlet的ID一致才能同意klusterlet的接入。这也就确保了如果bootstrap secret被不慎泄露后，CSR也不会被管理员轻易的接受。
klusterlet使用的客户证书是有过期时间的，klusterlet需要在证书过期之前使用现有的客户证书发起新的CSR请求来获取新的客户证书。hub集群会检验 更新证书的CSR请求是否合法并自动签署新的客户证书。需要注意的是由于klusterlet使用了动态ID的机制，只有klusterlet本身发起的CSR请求才会 被自动签署。如果klusterlet在集群中被卸载然后重新部署后，它必须重新使用bootstrap secret流程来获取客户证书。
认证和授权的分离 在klusterlet的CSR请求被接受后，它获得了被hub集群认证通过的客户证书，但是它在这个时候还没有对hub集群上特定资源访问的权限。 ocm中还有一个单独的授权流程。每个被管理集群的klusterlet时候有权限访问hub集群的特定资源是被对应ManagedClusterAPI上的 hubAcceptsClient域来控制的。只有当这个域被置位true时，hub集群的控制器才会为对应klusterlet赋予权限。而设置这个域需要用户 在hub集群中对managedcluster/accept具有update权限才可以。如下面的clusterrole的例子表示用户只能对cluster1这个 ManagedCluster上的klusterlet赋予权限。
apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: open-cluster-management:hub rules: - apiGroups: [&amp;#34;register.open-cluster-management.io&amp;#34;] resources: [&amp;#34;managedclusters/accept&amp;#34;] verbs: [&amp;#34;update&amp;#34;] resourceNames: [&amp;#34;cluster1&amp;#34;] 将认证和授权的流程分开的原因是通常情况下hub集群具有approve CSR权限的用户和&amp;quot;允许klusterlet接入hub&amp;quot;集群的用户并不完全一致。以上 机制就可以保证即使用户拥有approve CSR的权限也不能给任意的klusterlet赋予接入hub集群的权限。
实现细节 所有认证授权和秘钥管理的代码实现都在registration组件中。大概的流程 如下图所示
当registration-agent在被管理集群中启动后，会首先在自己的namespace里查找是否有hub-kubeconfig的秘钥并验证这个秘钥是否合法。 如果不存在或者不合法，registration-agent就进入了bootstrap流程，它会首先产生一个动态的agent ID, 然后使用一个更小权限的 bootstrap-kubeconfig来创建client和informer，接下来启动一个ClientCertForHubController的goroutine。这个controller会在hub集群 创建CSR,等待CSR中签署的证书并最终把证书和私钥做为名为hub-kubeconfig的秘钥持久化在被管理集群中。agent接着持续监控hub-kubeconfig 这个秘钥是否已经被持久化。当agent发现hub-kubeconfig则意味着agent已经获取到了可以访问hub集群的客户证书，agent就会停掉之前的controller并 退出bootstrap流程。接下来agent会重新用hub-kubeconfig创建client和informer，并启动一个新的ClientCertForHubController的goroutine 来定期刷新客户证书。</description></item><item><title>通过OCM访问不同VPC下的集群</title><link>https://open-cluster-management.io/blog/2022/%E9%80%9A%E8%BF%87ocm%E8%AE%BF%E9%97%AE%E4%B8%8D%E5%90%8Cvpc%E4%B8%8B%E7%9A%84%E9%9B%86%E7%BE%A4/</link><pubDate>Wed, 20 Apr 2022 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2022/%E9%80%9A%E8%BF%87ocm%E8%AE%BF%E9%97%AE%E4%B8%8D%E5%90%8Cvpc%E4%B8%8B%E7%9A%84%E9%9B%86%E7%BE%A4/</guid><description>问题背景 当我们拥有多个集群时，一个很常见的需求是：不同的用户希望能访问位于不同VPC下的集群。比如，开发人员希望能够在测试集群部署应用，或者运维人员希望能够在生产集群上进行故障排查。
作为多个集群的管理员，为了实现该需求，需要在各个集群为用户：
绑定Role。 提供访问配置（证书或Token）。 提供访问入口。 但是，这种方式有以下几个问题：
网络隔离：集群位于私有数据中心，那么管理员就需要为集群用户进行特殊的网络配置，比如建立VPN或者跳板机。 网络安全：为用户暴露的集群端口，会增加集群的安全风险。 配置过期：证书中的秘钥和Token都有过期时间，管理员需要定期为用户做配置更新。 而通过安装OCM以及cluster-proxy，managed-serviceaccount两个插件，管理员则可以在不暴露集群端口的情况下，为不同用户提供统一访问入口，并方便地管理不同用户的访问权限。
基本概念 以下，我们通过一个简单的例子来解释OCM以及cluster-proxy，managed-serviceaccount的基本概念。
假设我们有3个集群，分别位于两个不同的VPC中，其中VPC-1中的集群可以被所有用户访问，而VPC-2中的2个集群只能被管理员访问。
管理员希望通过VPC-1中的集群（后文称“管理集群”）为用户提供统一的访问入口，使用户可以访问VPC-2中的集群（后文称“受管集群”）。
OCM是什么？ OCM 全称为 Open Cluster Management，旨在解决多集群场景下的集群注册管理，工作负载分发，以及动态的资源配置等功能。
安装OCM之后，我们可以将受管集群注册加入管理集群，完成注册后，在管理集群中会创建一个与受管集群注册名相同的命名空间。比如，受管集群以cluster1注册到管理集群，那么就会对应创建一个名为cluster1的命名空间。在管理集群上，我们可以通过这些不同的命令空间来区分多个受管集群的资源。
注册过程不要求受管集群向管理集群暴露访问接口。
更多有关于OCM的架构细节，请参考官方文档。
cluster-proxy是什么？ cluster-proxy是使用OCM的addon-framework实现的一个基于 apiserver-network-proxy（后文简写为：ANP）的插件。插件安装后，会在管理集群上安装ANP的组件proxy-server，在受管集群上安装ANP的组件proxy-agent。
接着proxy-agent通过管理集群上暴露的端口，向proxy-server发送注册请求，并建立一条全双工通信的GRPC管道。
需要注意的是，cluster-proxy建立的GRPC通道只是保证了管理集群到被管理集群的网络连通性，如果用户想访问被管理集群的APIServer或者其他服务，仍需要从被管理集群获得相应的认证秘钥和权限。
更多有关cluster-proxy的信息，请参考官方文档。
managed-serviceaccount是什么？ Managed-serviceaccount（后文简写为：MSA）也是利用OCM的addon-framework实现的插件。
安装该插件后，可以在管理集群上配置ManagedServiceAcccount的CR，插件会根据此CR的spec配置，在目标受管集群的open-cluster-management-managed-serviceaccount命名空间内，创建一个与CR同名的ServiceAccount。
接着插件会将此ServiceAccount生成的对应token数据同步回管理集群，并在受管集群的命令空间中创建一个同名的Secret，用于保存该token。整个token的数据同步都是在OCM提供的MTLS连接中进行，从而确保token不会被第三方探查到。
由此集群管理员可以在hub上通过MSA来获得访问被管理集群APIServer的token。当然这个token现在还没有被赋予权限，只要管理员为该token绑定相应的Role，就可以实现访问被管理集群的权限控制。
更多有关managed-serviceaccount的信息，请参考官方文档。
样例 接下来通过一个简单的例子来演示如何使用OCM，cluster-proxy，managed-serviceaccount来实现跨VPC访问集群。
首先从管理员视角，我们通过脚本快速创建一个基于kind的多集群环境，其中具有一个管理集群（hub），以及两个受管集群（cluster1, cluster2）。并且 cluster1, cluster2 会通过 OCM 注册到了 hub。
该脚本还会为我们安装OCM的CLI工具clusteradm。
curl -L &amp;lt;https://raw.githubusercontent.com/open-cluster-management-io/OCM/main/solutions/setup-dev-environment/local-up.sh&amp;gt; | bash 然后，管理员还需要安装两个插件：
# 安装 cluster-proxy helm install \\ -n open-cluster-management-addon --create-namespace \\ cluster-proxy ocm/cluster-proxy # 安装 managed-service helm install \\ -n open-cluster-management-addon --create-namespace \\ managed-serviceaccount ocm/managed-serviceaccount # 验证 cluster-proxy 已安装 clusteradm get addon cluster-proxy # 验证 managed-serviceaccount 已安装 clusteradm get addon managed-serviceaccount 完成安装后，管理员希望给用户能够访问cluster1，他需要通过以下命令创建一个在hub的命令空间cluster1中，创建一个MSA的CR：</description></item><item><title>Using the Open Cluster Management Placement for Multicluster Scheduling</title><link>https://open-cluster-management.io/blog/2022/using-the-open-cluster-management-placement-for-multicluster-scheduling/</link><pubDate>Wed, 12 Jan 2022 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2022/using-the-open-cluster-management-placement-for-multicluster-scheduling/</guid><description>Read more at Red Hat Cloud Blog.</description></item><item><title>Using the Open Cluster Management Add-on Framework to Develop a Managed Cluster Add-on</title><link>https://open-cluster-management.io/blog/2021/using-the-open-cluster-management-add-on-framework-to-develop-a-managed-cluster-add-on/</link><pubDate>Tue, 12 Oct 2021 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2021/using-the-open-cluster-management-add-on-framework-to-develop-a-managed-cluster-add-on/</guid><description>Read more at Red Hat Cloud Blog.</description></item><item><title>The Next Kubernetes Frontier: Multicluster Management</title><link>https://open-cluster-management.io/blog/2021/the-next-kubernetes-frontier-multicluster-management/</link><pubDate>Wed, 22 Sep 2021 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2021/the-next-kubernetes-frontier-multicluster-management/</guid><description>Read more at Container Journal.</description></item><item><title>Put together a user walk through for the basic Open Cluster Management API using `kind`, `olm`, and other open source technologies</title><link>https://open-cluster-management.io/blog/2021/put-together-a-user-walk-through-for-the-basic-open-cluster-management-api-using-kind-olm-and-other-open-source-technologies/</link><pubDate>Mon, 24 May 2021 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2021/put-together-a-user-walk-through-for-the-basic-open-cluster-management-api-using-kind-olm-and-other-open-source-technologies/</guid><description>Read more at GitHub.</description></item><item><title>Setting up Open Cluster Management the hard way</title><link>https://open-cluster-management.io/blog/2021/setting-up-open-cluster-management-the-hard-way/</link><pubDate>Thu, 22 Apr 2021 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/blog/2021/setting-up-open-cluster-management-the-hard-way/</guid><description>Read more at Setting up Open Cluster Management the hard way.</description></item></channel></rss>