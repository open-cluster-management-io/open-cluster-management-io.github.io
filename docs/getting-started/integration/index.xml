<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Add-ons and Integrations on Open Cluster Management</title><link>https://open-cluster-management.io/docs/getting-started/integration/</link><description>Recent content in Add-ons and Integrations on Open Cluster Management</description><generator>Hugo</generator><language>en</language><atom:link href="https://open-cluster-management.io/docs/getting-started/integration/index.xml" rel="self" type="application/rss+xml"/><item><title>Application lifecycle management</title><link>https://open-cluster-management.io/docs/getting-started/integration/app-lifecycle/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/docs/getting-started/integration/app-lifecycle/</guid><description>&lt;p&gt;After the setup of Open Cluster Management (OCM) hub and managed clusters,
you could install the OCM built-in application management add-on.
The OCM application management add-on leverages the
&lt;a href="https://argo-cd.readthedocs.io/"&gt;Argo CD&lt;/a&gt;
to provide declarative GitOps based application lifecycle management across multiple Kubernetes clusters.&lt;/p&gt;
&lt;h2 id="architecture"&gt;Architecture&lt;/h2&gt;
&lt;p&gt;Traditional Argo CD resource delivery primarily uses a push model,
where resources are deployed from a centralized Argo CD instance to remote or managed clusters.&lt;/p&gt;
&lt;div style="text-align: center; padding: 20px;"&gt;
 &lt;img src="https://github.com/open-cluster-management-io/argocd-pull-integration/raw/main/assets/push.png" alt="Argo CD Push Model" style="margin: 0 auto; width: 80%"&gt;
&lt;/div&gt;
&lt;p&gt;With the OCM Argo CD add-on, users can leverage a pull based resource delivery model,
where managed clusters pull and apply application configurations.&lt;/p&gt;</description></item><item><title>Cluster proxy</title><link>https://open-cluster-management.io/docs/getting-started/integration/cluster-proxy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/docs/getting-started/integration/cluster-proxy/</guid><description>&lt;p&gt;&lt;a href="https://github.com/open-cluster-management-io/cluster-proxy"&gt;Cluster proxy&lt;/a&gt;
is an OCM addon providing L4 network connectivity from hub cluster to
the managed clusters without &lt;strong&gt;any additional requirement&lt;/strong&gt; to the managed
cluster&amp;rsquo;s network infrastructure by leveraging the Kubernetes official SIG
sub-project &lt;a href="https://github.com/kubernetes-sigs/apiserver-network-proxy"&gt;apiserver-network-proxy&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="background"&gt;Background&lt;/h2&gt;
&lt;p&gt;The original architecture of OCM allows a cluster from anywhere to be
registered and managed by OCM&amp;rsquo;s control plane (i.e. the hub cluster)
as long as a &lt;a href="https://open-cluster-management.io/docs/getting-started/installation/register-a-cluster/"&gt;klusterlet agent&lt;/a&gt;
can reach hub cluster&amp;rsquo;s endpoint. So the minimal requirement for the
managed cluster&amp;rsquo;s network infrastructure in OCM is &amp;ldquo;klusterlet -&amp;gt; hub&amp;rdquo;
connectivity. However, there are still some cases where the components
in the hub cluster hope to proactively dail/request the services in the
managed clusters which will need the &amp;ldquo;hub -&amp;gt; klusterlet&amp;rdquo; connectivity on
the other hand. In addition to that, the cases can be even more complex
when each of the managed clusters are not in the same network.&lt;/p&gt;</description></item><item><title>Managed service account</title><link>https://open-cluster-management.io/docs/getting-started/integration/managed-serviceaccount/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/docs/getting-started/integration/managed-serviceaccount/</guid><description>&lt;p&gt;&lt;a href="https://github.com/open-cluster-management-io/managed-serviceaccount"&gt;Managed Service Account&lt;/a&gt;
is an OCM addon enabling a hub cluster admin to manage &lt;a href="https://kubernetes.io/docs/reference/access-authn-authz/service-accounts-admin/"&gt;service account&lt;/a&gt;
across multiple clusters on ease. By controlling the creation and removal of
the service account, the addon agent will project and rotate the corresponding
token back to the hub cluster which is very useful for the Kube API client from
the hub cluster to request against the managed clusters.&lt;/p&gt;
&lt;h2 id="background"&gt;Background&lt;/h2&gt;
&lt;p&gt;Normally there are two major approaches for a Kube API client to authenticate
and access a Kubernetes cluster:&lt;/p&gt;</description></item><item><title>Multicluster Control Plane</title><link>https://open-cluster-management.io/docs/getting-started/integration/multicluster-controlplane/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/docs/getting-started/integration/multicluster-controlplane/</guid><description>&lt;h2 id="what-is-multicluster-control-plane"&gt;What is &lt;code&gt;Multicluster Control Plane&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;The multicluster control plane is a lightweight Open Cluster Manager (OCM) control plane that is easy to install and has a small footprint. It can be running anywhere with or without a Kubernetes environment to serve the OCM control plane capabilities.&lt;/p&gt;
&lt;h2 id="why-use-multicluster-control-plane"&gt;Why use &lt;code&gt;Multicluster Control Plane&lt;/code&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Some Kubernetes environments do not have CSR (e.g., EKS) so that the standard OCM control plane cannot be installed. The multicluster control plane can be able to install in these environments and expose the OCM control plane API via loadbalancer.&lt;/p&gt;</description></item><item><title>FleetConfig Controller</title><link>https://open-cluster-management.io/docs/getting-started/integration/fleetconfig-controller/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://open-cluster-management.io/docs/getting-started/integration/fleetconfig-controller/</guid><description>&lt;h2 id="what-is-the-fleetconfig-controller"&gt;What is the &lt;code&gt;FleetConfig Controller&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;The (&lt;a href="https://github.com/open-cluster-management-io/lab/tree/main/fleetconfig-controller"&gt;https://github.com/open-cluster-management-io/lab/tree/main/fleetconfig-controller&lt;/a&gt;) introduces 2 new custom resources to the OCM ecosystem: &lt;code&gt;Hub&lt;/code&gt; and &lt;code&gt;Spoke&lt;/code&gt; . It reconciles &lt;code&gt;Hub&lt;/code&gt; and &lt;code&gt;Spoke&lt;/code&gt; resources to declaratively manage the lifecycle of Open Cluster Management (OCM) multi-clusters.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;fleetconfig-controller&lt;/code&gt; will initialize an OCM hub and one or more spoke clusters; add, remove, and upgrade clustermanagers and klusterlets when their bundle versions change, manage their feature gates, and uninstall all OCM components properly whenever a &lt;code&gt;Hub&lt;/code&gt; or &lt;code&gt;Spoke&lt;/code&gt; is deleted.&lt;/p&gt;</description></item></channel></rss>